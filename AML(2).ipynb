{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kahram-y/AML_project/blob/main/AML(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "금융결제원 AML 탐지 프로젝트\n",
        "\n",
        "IBM Transactions for Anti Money Laundering 데이터셋 활용\n",
        "\n",
        "목표: 자금세탁 계좌 탐지 (노드 분류)\n",
        "\n",
        "프로젝트 구조:\n",
        "1. 데이터 탐색 및 전처리\n",
        "2. 문제 정의\n",
        "3. 피쳐 생성 (집계 피쳐 + 그래프 피쳐)\n",
        "4. 모델 학습 및 평가\n",
        "   - Baseline: XGBoost/CatBoost\n",
        "   - 시계열 모델 앙상블\n",
        "   - 그래프 피쳐 추가\n",
        "   - GNN 모델"
      ],
      "metadata": {
        "id": "30Iz9L_66xpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn xgboost catboost lightgbm networkx matplotlib seaborn imbalanced-learn shap"
      ],
      "metadata": {
        "id": "r8R6ZcAv6x-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1a983e-a4a2-465a-ce7a-7d4d00c948ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.3)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.1)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.50.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (0.1.5)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "import lightgbm as lgb\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "tC91O4zh698v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 파일 경로\n",
        "trans_path = '/content/drive/MyDrive/HI-Small_Trans.csv'\n",
        "accounts_path = '/content/drive/MyDrive/HI-Small_accounts.csv'"
      ],
      "metadata": {
        "id": "riICG9oD6vzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b885e3-827d-4ac6-fe8e-5a7cb29ef1c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# 1. 데이터 로드 및 탐색\n",
        "# ====================================\n",
        "\n",
        "class AMLDataLoader:\n",
        "    \"\"\"AML 데이터 로드 및 초기 탐색\"\"\"\n",
        "\n",
        "    def __init__(self, trans_path, accounts_path):\n",
        "        self.trans_path = trans_path\n",
        "        self.accounts_path = accounts_path\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"데이터 로드\"\"\"\n",
        "        print(\"=\" * 80)\n",
        "        print(\"데이터 로딩 중...\")\n",
        "\n",
        "        # 거래 데이터 로드\n",
        "        self.transactions = pd.read_csv(self.trans_path)\n",
        "\n",
        "        # 계좌 데이터 로드\n",
        "        self.accounts = pd.read_csv(self.accounts_path)\n",
        "\n",
        "        print(f\"거래 데이터 shape: {self.transactions.shape}\")\n",
        "        print(f\"계좌 데이터 shape: {self.accounts.shape}\")\n",
        "\n",
        "        return self.transactions, self.accounts\n",
        "\n",
        "    def explore_data(self, df_trans, df_accounts):\n",
        "        \"\"\"데이터 탐색\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"데이터 탐색\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # 거래 데이터 기본 정보\n",
        "        print(\"\\n[거래 데이터 샘플]\")\n",
        "        print(df_trans.head())\n",
        "        print(f\"\\n컬럼: {df_trans.columns.tolist()}\")\n",
        "        print(f\"\\n결측치:\\n{df_trans.isnull().sum()}\")\n",
        "\n",
        "        # Is Laundering 분포\n",
        "        if 'Is Laundering' in df_trans.columns:\n",
        "            laundering_dist = df_trans['Is Laundering'].value_counts()\n",
        "            print(f\"\\n[자금세탁 분포]\")\n",
        "            print(laundering_dist)\n",
        "            print(f\"자금세탁 비율: {laundering_dist[1] / len(df_trans) * 100:.4f}%\")\n",
        "\n",
        "        # 시간 정보 파싱 및 분포 확인\n",
        "        df_trans['Timestamp'] = pd.to_datetime(df_trans['Timestamp'])\n",
        "        df_trans['Year'] = df_trans['Timestamp'].dt.year\n",
        "        df_trans['Month'] = df_trans['Timestamp'].dt.month\n",
        "        df_trans['Day'] = df_trans['Timestamp'].dt.day\n",
        "        df_trans['Hour'] = df_trans['Timestamp'].dt.hour\n",
        "        df_trans['DayOfWeek'] = df_trans['Timestamp'].dt.dayofweek\n",
        "\n",
        "        print(f\"\\n[시간 범위]\")\n",
        "        print(f\"시작: {df_trans['Timestamp'].min()}\")\n",
        "        print(f\"종료: {df_trans['Timestamp'].max()}\")\n",
        "\n",
        "        # Day별 자금세탁 분포 확인\n",
        "        if 'Is Laundering' in df_trans.columns:\n",
        "            day_dist = df_trans.groupby('Day')['Is Laundering'].agg(['sum', 'count', 'mean'])\n",
        "            print(f\"\\n[일별 자금세탁 분포]\")\n",
        "            print(day_dist)\n",
        "\n",
        "            # 치우침 확인\n",
        "            if day_dist['mean'].std() > 0.1:\n",
        "                print(\"\\n⚠️ Day 피쳐의 label 분포가 치우쳐져 있습니다. 제거 고려 필요\")\n",
        "\n",
        "        # 계좌 데이터 정보\n",
        "        print(f\"\\n[계좌 데이터 샘플]\")\n",
        "        print(df_accounts.head())\n",
        "\n",
        "        # Bank Name 분포 확인\n",
        "        if 'Bank Name' in df_accounts.columns:\n",
        "            print(f\"\\n은행 분포:\\n{df_accounts['Bank Name'].value_counts().head(10)}\")\n",
        "\n",
        "        return df_trans\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 2. 데이터 전처리 및 샘플링\n",
        "# ====================================\n",
        "\n",
        "class AMLPreprocessor:\n",
        "    \"\"\"데이터 전처리 및 샘플링\"\"\"\n",
        "\n",
        "    def __init__(self, sample_ratio=0.1, random_state=42):\n",
        "        self.sample_ratio = sample_ratio\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def create_hourly_samples(self, df_trans):\n",
        "        \"\"\"시간 단위 배치로 모델 단위 생성\n",
        "        각 계좌번호 + 시간 단위로 샘플 생성\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"시간 단위 배치 샘플 생성\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # From Account 기준 샘플 생성\n",
        "        from_samples = df_trans.copy()\n",
        "        from_samples['Account'] = from_samples['From Bank'].astype(str) + '_' + from_samples['Account'].astype(str)\n",
        "        from_samples['TimeUnit'] = from_samples['Timestamp'].dt.strftime('%Y-%m-%d %H')\n",
        "        from_samples['Direction'] = 'OUT'\n",
        "\n",
        "        # To Account 기준 샘플 생성\n",
        "        to_samples = df_trans.copy()\n",
        "        to_samples['Account'] = to_samples['To Bank'].astype(str) + '_' + to_samples['Account.1'].astype(str)\n",
        "        to_samples['TimeUnit'] = to_samples['Timestamp'].dt.strftime('%Y-%m-%d %H')\n",
        "        to_samples['Direction'] = 'IN'\n",
        "\n",
        "        # 합치기\n",
        "        all_samples = pd.concat([from_samples, to_samples], ignore_index=True)\n",
        "\n",
        "        # 계좌 + 시간 단위로 그룹화하여 label 결정\n",
        "        # Is Laundering=1인 거래가 하나라도 있으면 해당 시간의 계좌는 suspicious\n",
        "        account_time_labels = all_samples.groupby(['Account', 'TimeUnit']).agg({\n",
        "            'Is Laundering': 'max',  # 하나라도 1이면 1\n",
        "            'Timestamp': 'min'\n",
        "        }).reset_index()\n",
        "\n",
        "        account_time_labels.rename(columns={'Timestamp': 'TimeUnit_Start'}, inplace=True)\n",
        "\n",
        "        print(f\"총 샘플 수 (계좌-시간 단위): {len(account_time_labels)}\")\n",
        "        print(f\"자금세탁 샘플: {account_time_labels['Is Laundering'].sum()}\")\n",
        "\n",
        "        return all_samples, account_time_labels\n",
        "\n",
        "    def stratified_sample(self, df, target_col='Is Laundering'):\n",
        "        \"\"\"계층화 샘플링\"\"\"\n",
        "        print(f\"\\n계층화 샘플링 (비율: {self.sample_ratio})\")\n",
        "\n",
        "        # 클래스별로 샘플링\n",
        "        sampled_dfs = []\n",
        "        for label in df[target_col].unique():\n",
        "            label_df = df[df[target_col] == label]\n",
        "            n_samples = int(len(label_df) * self.sample_ratio)\n",
        "            sampled = label_df.sample(n=n_samples, random_state=self.random_state)\n",
        "            sampled_dfs.append(sampled)\n",
        "\n",
        "        result = pd.concat(sampled_dfs, ignore_index=True)\n",
        "        print(f\"샘플링 후 크기: {len(result)}\")\n",
        "        print(f\"자금세탁 비율: {result[target_col].sum() / len(result) * 100:.4f}%\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def analyze_laundering_patterns(self, df_trans):\n",
        "        \"\"\"자금세탁 건과 정상 건의 차이 분석\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"자금세탁 패턴 분석\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        laundering = df_trans[df_trans['Is Laundering'] == 1]\n",
        "        normal = df_trans[df_trans['Is Laundering'] == 0]\n",
        "\n",
        "        # 거래 금액 비교\n",
        "        print(f\"\\n[거래 금액 통계]\")\n",
        "        print(f\"자금세탁 - 평균: ${laundering['Amount Received'].mean():.2f}, \"\n",
        "              f\"중앙값: ${laundering['Amount Received'].median():.2f}\")\n",
        "        print(f\"정상 거래 - 평균: ${normal['Amount Received'].mean():.2f}, \"\n",
        "              f\"중앙값: ${normal['Amount Received'].median():.2f}\")\n",
        "\n",
        "        # 결제 수단 분포\n",
        "        print(f\"\\n[결제 수단 분포]\")\n",
        "        print(\"자금세탁:\")\n",
        "        print(laundering['Receiving Currency'].value_counts().head())\n",
        "        print(\"\\n정상 거래:\")\n",
        "        print(normal['Receiving Currency'].value_counts().head())\n",
        "\n",
        "        # 시간대 분포\n",
        "        print(f\"\\n[시간대 분포]\")\n",
        "        print(\"자금세탁 - 시간대별:\")\n",
        "        print(laundering['Hour'].value_counts().sort_index())\n",
        "\n",
        "        return laundering, normal\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 3. 피쳐 생성\n",
        "# ====================================\n",
        "\n",
        "class FeatureEngineer:\n",
        "    \"\"\"집계 피쳐 및 그래프 피쳐 생성\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.feature_names = []\n",
        "\n",
        "    def create_aggregation_features(self, df_trans, account_time_df):\n",
        "        \"\"\"50개 이상의 집계 피쳐 생성\n",
        "        과거 정보만 사용 (Data Leakage 방지)\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"집계 피쳐 생성\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        features_list = []\n",
        "\n",
        "        for idx, row in account_time_df.iterrows():\n",
        "            if idx % 10000 == 0:\n",
        "                print(f\"진행: {idx}/{len(account_time_df)}\")\n",
        "\n",
        "            account = row['Account']\n",
        "            time_unit = pd.to_datetime(row['TimeUnit_Start'])\n",
        "\n",
        "            # 해당 계좌의 과거 거래만 필터링\n",
        "            past_trans = df_trans[\n",
        "                (df_trans['Account'] == account) &\n",
        "                (df_trans['Timestamp'] < time_unit)\n",
        "            ].copy()\n",
        "\n",
        "            if len(past_trans) == 0:\n",
        "                # 과거 거래가 없으면 기본값\n",
        "                features = self._default_features(account, time_unit)\n",
        "            else:\n",
        "                features = self._compute_features(past_trans, account, time_unit)\n",
        "\n",
        "            features_list.append(features)\n",
        "\n",
        "            if idx >= 1000:  # 시연용으로 1000건만\n",
        "                break\n",
        "\n",
        "        feature_df = pd.DataFrame(features_list)\n",
        "        self.feature_names = [c for c in feature_df.columns\n",
        "                             if c not in ['Account', 'TimeUnit']]\n",
        "\n",
        "        print(f\"\\n생성된 피쳐 수: {len(self.feature_names)}\")\n",
        "        print(f\"피쳐 목록 (처음 10개): {self.feature_names[:10]}\")\n",
        "\n",
        "        return feature_df\n",
        "\n",
        "    def _compute_features(self, past_trans, account, time_unit):\n",
        "        \"\"\"실제 피쳐 계산\"\"\"\n",
        "        features = {'Account': account, 'TimeUnit': str(time_unit)}\n",
        "\n",
        "        # 시간 윈도우 정의\n",
        "        windows = {\n",
        "            '1h': timedelta(hours=1),\n",
        "            '3h': timedelta(hours=3),\n",
        "            '1d': timedelta(days=1),\n",
        "            '7d': timedelta(days=7)\n",
        "        }\n",
        "\n",
        "        for window_name, window_delta in windows.items():\n",
        "            window_start = time_unit - window_delta\n",
        "            window_trans = past_trans[past_trans['Timestamp'] >= window_start]\n",
        "\n",
        "            # OUT 거래 (송금)\n",
        "            out_trans = window_trans[window_trans['Direction'] == 'OUT']\n",
        "            features[f'out_count_{window_name}'] = len(out_trans)\n",
        "            features[f'out_amount_sum_{window_name}'] = float(out_trans['Amount Paid'].sum()) if len(out_trans) > 0 else 0.0\n",
        "            features[f'out_amount_mean_{window_name}'] = float(out_trans['Amount Paid'].mean()) if len(out_trans) > 0 else 0.0\n",
        "            features[f'out_amount_std_{window_name}'] = float(out_trans['Amount Paid'].std()) if len(out_trans) > 0 else 0.0\n",
        "            features[f'out_amount_max_{window_name}'] = float(out_trans['Amount Paid'].max()) if len(out_trans) > 0 else 0.0\n",
        "\n",
        "            # IN 거래 (입금)\n",
        "            in_trans = window_trans[window_trans['Direction'] == 'IN']\n",
        "            features[f'in_count_{window_name}'] = len(in_trans)\n",
        "            features[f'in_amount_sum_{window_name}'] = float(in_trans['Amount Received'].sum()) if len(in_trans) > 0 else 0.0\n",
        "            features[f'in_amount_mean_{window_name}'] = float(in_trans['Amount Received'].mean()) if len(in_trans) > 0 else 0.0\n",
        "            features[f'in_amount_std_{window_name}'] = float(in_trans['Amount Received'].std()) if len(in_trans) > 0 else 0.0\n",
        "            features[f'in_amount_max_{window_name}'] = float(in_trans['Amount Received'].max()) if len(in_trans) > 0 else 0.0\n",
        "\n",
        "            # 순 흐름\n",
        "            features[f'net_flow_{window_name}'] = (\n",
        "                features[f'in_amount_sum_{window_name}'] -\n",
        "                features[f'out_amount_sum_{window_name}']\n",
        "            )\n",
        "\n",
        "            # 외화 거래\n",
        "            foreign_curr = window_trans[\n",
        "                window_trans['Payment Currency'] != window_trans['Receiving Currency']\n",
        "            ]\n",
        "            features[f'foreign_count_{window_name}'] = len(foreign_curr)\n",
        "            features[f'foreign_ratio_{window_name}'] = (\n",
        "                len(foreign_curr) / len(window_trans) if len(window_trans) > 0 else 0\n",
        "            )\n",
        "\n",
        "        # 전체 거래 통계\n",
        "        features['total_trans_count'] = len(past_trans)\n",
        "        out_total = past_trans[past_trans['Direction'] == 'OUT']['Amount Paid'].sum()\n",
        "        in_total = past_trans[past_trans['Direction'] == 'IN']['Amount Received'].sum()\n",
        "        features['total_out_amount'] = float(out_total) if pd.notna(out_total) else 0.0\n",
        "        features['total_in_amount'] = float(in_total) if pd.notna(in_total) else 0.0\n",
        "\n",
        "        # 거래 상대방 다양성 - 'Account' 컬럼이 충돌할 수 있으므로 다른 방법 사용\n",
        "        # From/To 계좌의 유니크 수 계산\n",
        "        unique_from = past_trans[past_trans['Direction'] == 'OUT']['From Bank'].astype(str) + '_' + past_trans[past_trans['Direction'] == 'OUT']['Account'].astype(str)\n",
        "        unique_to = past_trans[past_trans['Direction'] == 'IN']['To Bank'].astype(str) + '_' + past_trans[past_trans['Direction'] == 'IN']['Account.1'].astype(str)\n",
        "        features['unique_counterparties'] = len(set(unique_from.tolist() + unique_to.tolist()))\n",
        "\n",
        "        # 결제 수단 다양성\n",
        "        features['unique_currencies'] = past_trans['Payment Currency'].nunique()\n",
        "\n",
        "        # 시간대 분포\n",
        "        hour_dist = past_trans['Hour'].value_counts()\n",
        "        features['night_trans_ratio'] = (\n",
        "            hour_dist[(hour_dist.index >= 0) & (hour_dist.index < 6)].sum() /\n",
        "            len(past_trans) if len(past_trans) > 0 else 0\n",
        "        )\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _default_features(self, account, time_unit):\n",
        "        \"\"\"과거 거래가 없을 때 기본 피쳐\"\"\"\n",
        "        features = {'Account': account, 'TimeUnit': str(time_unit)}\n",
        "\n",
        "        # 모든 피쳐를 0으로 초기화\n",
        "        windows = ['1h', '3h', '1d', '7d']\n",
        "        for window in windows:\n",
        "            for prefix in ['out', 'in']:\n",
        "                for metric in ['count', 'amount_sum', 'amount_mean', 'amount_std', 'amount_max']:\n",
        "                    features[f'{prefix}_{metric}_{window}'] = 0\n",
        "            features[f'net_flow_{window}'] = 0\n",
        "            features[f'foreign_count_{window}'] = 0\n",
        "            features[f'foreign_ratio_{window}'] = 0\n",
        "\n",
        "        features['total_trans_count'] = 0\n",
        "        features['total_out_amount'] = 0\n",
        "        features['total_in_amount'] = 0\n",
        "        features['unique_counterparties'] = 0\n",
        "        features['unique_currencies'] = 0\n",
        "        features['night_trans_ratio'] = 0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def create_graph_features(self, df_trans, account_time_df):\n",
        "        \"\"\"그래프 기반 피쳐 생성\n",
        "        - Centrality 기반 (Degree, Closeness, Betweenness)\n",
        "        - Path & Flow 패턴\n",
        "        - Community 구조\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"그래프 피쳐 생성\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # 거래 네트워크 구축\n",
        "        G = nx.DiGraph()\n",
        "\n",
        "        for _, row in df_trans.iterrows():\n",
        "            from_acc = str(row['From Bank']) + '_' + str(row['Account'])\n",
        "            to_acc = str(row['To Bank']) + '_' + str(row['Account.1'])\n",
        "\n",
        "            # Amount Paid를 float으로 변환\n",
        "            try:\n",
        "                amount = float(row['Amount Paid'])\n",
        "            except (ValueError, TypeError):\n",
        "                amount = 0.0\n",
        "\n",
        "            if G.has_edge(from_acc, to_acc):\n",
        "                G[from_acc][to_acc]['weight'] += amount\n",
        "                G[from_acc][to_acc]['count'] += 1\n",
        "            else:\n",
        "                G.add_edge(from_acc, to_acc, weight=amount, count=1)\n",
        "\n",
        "        print(f\"그래프 구축 완료 - 노드: {G.number_of_nodes()}, 엣지: {G.number_of_edges()}\")\n",
        "\n",
        "        # Centrality 계산\n",
        "        print(\"Centrality 계산 중...\")\n",
        "        degree_centrality = nx.degree_centrality(G)\n",
        "        in_degree_centrality = nx.in_degree_centrality(G)\n",
        "        out_degree_centrality = nx.out_degree_centrality(G)\n",
        "\n",
        "        # Betweenness는 계산량이 많으므로 샘플링\n",
        "        sample_nodes = list(G.nodes())[:min(1000, len(G.nodes()))]\n",
        "        betweenness_centrality = nx.betweenness_centrality(\n",
        "            G.subgraph(sample_nodes),\n",
        "            weight='weight'\n",
        "        )\n",
        "\n",
        "        # PageRank\n",
        "        pagerank = nx.pagerank(G, weight='weight')\n",
        "\n",
        "        # 그래프 피쳐를 데이터프레임에 추가\n",
        "        graph_features = []\n",
        "\n",
        "        for _, row in account_time_df.iterrows():\n",
        "            account = row['Account']\n",
        "\n",
        "            features = {\n",
        "                'Account': account,\n",
        "                'TimeUnit': row['TimeUnit'],\n",
        "                'degree_centrality': degree_centrality.get(account, 0),\n",
        "                'in_degree_centrality': in_degree_centrality.get(account, 0),\n",
        "                'out_degree_centrality': out_degree_centrality.get(account, 0),\n",
        "                'betweenness_centrality': betweenness_centrality.get(account, 0),\n",
        "                'pagerank': pagerank.get(account, 0),\n",
        "            }\n",
        "\n",
        "            # 이웃 노드 정보\n",
        "            if account in G:\n",
        "                successors = list(G.successors(account))\n",
        "                predecessors = list(G.predecessors(account))\n",
        "\n",
        "                features['num_successors'] = len(successors)\n",
        "                features['num_predecessors'] = len(predecessors)\n",
        "                features['total_out_weight'] = float(sum(G[account][s]['weight'] for s in successors))\n",
        "                features['total_in_weight'] = float(sum(G[p][account]['weight'] for p in predecessors))\n",
        "            else:\n",
        "                features['num_successors'] = 0\n",
        "                features['num_predecessors'] = 0\n",
        "                features['total_out_weight'] = 0.0\n",
        "                features['total_in_weight'] = 0.0\n",
        "\n",
        "            graph_features.append(features)\n",
        "\n",
        "        graph_feature_df = pd.DataFrame(graph_features)\n",
        "\n",
        "        print(f\"그래프 피쳐 생성 완료 - 피쳐 수: {len(graph_feature_df.columns) - 2}\")\n",
        "\n",
        "        return graph_feature_df\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 4. 모델 학습 및 평가\n",
        "# ====================================\n",
        "\n",
        "class AMLModelTrainer:\n",
        "    \"\"\"모델 학습 및 평가\"\"\"\n",
        "\n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "        self.models = {}\n",
        "        self.results = {}\n",
        "\n",
        "    def prepare_train_test_split(self, feature_df, label_df, test_size=0.3):\n",
        "        \"\"\"시계열 기준 train/test 분할\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Train/Test 분할\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # 피쳐와 라벨 병합\n",
        "        merged = feature_df.merge(\n",
        "            label_df[['Account', 'TimeUnit', 'Is Laundering']],\n",
        "            on=['Account', 'TimeUnit'],\n",
        "            how='inner'\n",
        "        )\n",
        "\n",
        "        # 시간순 정렬\n",
        "        merged = merged.sort_values('TimeUnit')\n",
        "\n",
        "        # 시간 기준 분할\n",
        "        split_idx = int(len(merged) * (1 - test_size))\n",
        "        train_df = merged.iloc[:split_idx]\n",
        "        test_df = merged.iloc[split_idx:]\n",
        "\n",
        "        print(f\"Train set: {len(train_df)} (자금세탁: {train_df['Is Laundering'].sum()})\")\n",
        "        print(f\"Test set: {len(test_df)} (자금세탁: {test_df['Is Laundering'].sum()})\")\n",
        "        print(f\"Train 자금세탁 비율: {train_df['Is Laundering'].mean():.4%}\")\n",
        "        print(f\"Test 자금세탁 비율: {test_df['Is Laundering'].mean():.4%}\")\n",
        "\n",
        "        # Feature와 Label 분리\n",
        "        feature_cols = [c for c in merged.columns\n",
        "                       if c not in ['Account', 'TimeUnit', 'Is Laundering']]\n",
        "\n",
        "        X_train = train_df[feature_cols]\n",
        "        y_train = train_df['Is Laundering']\n",
        "        X_test = test_df[feature_cols]\n",
        "        y_test = test_df['Is Laundering']\n",
        "\n",
        "        return X_train, X_test, y_train, y_test, test_df\n",
        "\n",
        "    def train_baseline_model(self, X_train, y_train, X_test, y_test,\n",
        "                            use_smote=False, scale_pos_weight=None):\n",
        "        \"\"\"Baseline: XGBoost/CatBoost\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Baseline 모델 학습 (XGBoost)\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # 데이터 검증\n",
        "        print(f\"학습 데이터: {len(X_train)}건\")\n",
        "        print(f\"테스트 데이터: {len(X_test)}건\")\n",
        "        print(f\"Positive 비율 (Train): {y_train.sum() / len(y_train) * 100:.4f}%\")\n",
        "        print(f\"Positive 비율 (Test): {y_test.sum() / len(y_test) * 100:.4f}%\")\n",
        "\n",
        "        # NaN 값 처리\n",
        "        X_train = X_train.fillna(0)\n",
        "        X_test = X_test.fillna(0)\n",
        "\n",
        "        # Inf 값 처리\n",
        "        X_train = X_train.replace([np.inf, -np.inf], 0)\n",
        "        X_test = X_test.replace([np.inf, -np.inf], 0)\n",
        "\n",
        "        # SMOTE 적용 여부\n",
        "        if use_smote and y_train.sum() > 0:\n",
        "            print(\"SMOTE 오버샘플링 적용 중...\")\n",
        "            try:\n",
        "                smote = SMOTE(random_state=self.random_state)\n",
        "                X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "                print(f\"SMOTE 후 - Positive: {y_train_res.sum()}, Negative: {len(y_train_res) - y_train_res.sum()}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ SMOTE 실패: {e}\")\n",
        "                print(\"원본 데이터로 학습합니다.\")\n",
        "                X_train_res, y_train_res = X_train, y_train\n",
        "        else:\n",
        "            X_train_res, y_train_res = X_train, y_train\n",
        "\n",
        "        # scale_pos_weight 계산\n",
        "        if scale_pos_weight is None:\n",
        "            if y_train_res.sum() > 0:\n",
        "                scale_pos_weight = (len(y_train_res) - y_train_res.sum()) / y_train_res.sum()\n",
        "            else:\n",
        "                print(\"⚠️ 학습 데이터에 Positive 샘플이 없습니다!\")\n",
        "                scale_pos_weight = 1.0\n",
        "\n",
        "        print(f\"scale_pos_weight: {scale_pos_weight:.2f}\")\n",
        "\n",
        "        # base_score 계산 (0과 1 사이로 제한)\n",
        "        positive_ratio = y_train_res.sum() / len(y_train_res)\n",
        "        base_score = max(0.01, min(0.99, positive_ratio))  # 0.01 ~ 0.99 범위로 제한\n",
        "\n",
        "        print(f\"base_score: {base_score:.4f}\")\n",
        "\n",
        "        # XGBoost 학습\n",
        "        xgb_model = xgb.XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            scale_pos_weight=scale_pos_weight,\n",
        "            base_score=base_score,  # 명시적으로 설정\n",
        "            random_state=self.random_state,\n",
        "            eval_metric='logloss',  # auc 대신 logloss 사용\n",
        "            use_label_encoder=False\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            xgb_model.fit(X_train_res, y_train_res, verbose=False)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ XGBoost 학습 실패: {e}\")\n",
        "            print(\"CatBoost로 전환합니다...\")\n",
        "\n",
        "            # CatBoost로 대체\n",
        "            from catboost import CatBoostClassifier\n",
        "            xgb_model = CatBoostClassifier(\n",
        "                iterations=100,\n",
        "                depth=6,\n",
        "                learning_rate=0.1,\n",
        "                loss_function='Logloss',\n",
        "                random_state=self.random_state,\n",
        "                verbose=False\n",
        "            )\n",
        "            xgb_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "        # 예측\n",
        "        y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # 모델 저장\n",
        "        self.models['baseline_xgb'] = xgb_model\n",
        "\n",
        "        print(\"학습 완료!\")\n",
        "\n",
        "        return xgb_model, y_pred_proba\n",
        "\n",
        "    def evaluate_topk(self, y_true, y_pred_proba, test_df, k_values=[50, 100, 200, 500]):\n",
        "        \"\"\"Top-K 평가\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Top-K 평가\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        # 점수 스케일링 (1000점 만점)\n",
        "        scores = (y_pred_proba - y_pred_proba.min()) / (y_pred_proba.max() - y_pred_proba.min()) * 1000\n",
        "\n",
        "        for k in k_values:\n",
        "            # Top K 선택\n",
        "            top_k_idx = np.argsort(y_pred_proba)[-k:]\n",
        "            y_pred_topk = np.zeros(len(y_true))\n",
        "            y_pred_topk[top_k_idx] = 1\n",
        "\n",
        "            # 메트릭 계산\n",
        "            precision = precision_score(y_true, y_pred_topk, zero_division=0)\n",
        "            recall = recall_score(y_true, y_pred_topk, zero_division=0)\n",
        "            f1 = f1_score(y_true, y_pred_topk, zero_division=0)\n",
        "\n",
        "            detected_laundering = y_true[top_k_idx].sum()\n",
        "            total_laundering = y_true.sum()\n",
        "\n",
        "            results[f'top_{k}'] = {\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1,\n",
        "                'detected': detected_laundering,\n",
        "                'total': total_laundering\n",
        "            }\n",
        "\n",
        "            print(f\"\\nTop-{k} 결과:\")\n",
        "            print(f\"  Precision: {precision:.4f}\")\n",
        "            print(f\"  Recall: {recall:.4f}\")\n",
        "            print(f\"  F1-Score: {f1:.4f}\")\n",
        "            print(f\"  탐지된 자금세탁: {detected_laundering}/{total_laundering}\")\n",
        "\n",
        "        # 점수 구간별 분포\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"점수 구간별 분포\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        bins = range(0, 1001, 100)\n",
        "        score_bins = pd.cut(scores, bins=bins, right=False)\n",
        "\n",
        "        for bin_range in score_bins.cat.categories:\n",
        "            mask = score_bins == bin_range\n",
        "            bin_positive = y_true[mask].sum()\n",
        "            bin_negative = len(y_true[mask]) - bin_positive\n",
        "\n",
        "            print(f\"{bin_range}: 정상={bin_negative}, 자금세탁={bin_positive}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def explain_with_shap(self, model, X_train, X_test, feature_names):\n",
        "        \"\"\"SHAP을 이용한 피쳐 중요도 분석\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"XAI: SHAP 피쳐 중요도 분석\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        try:\n",
        "            import shap\n",
        "\n",
        "            # SHAP 값 계산\n",
        "            explainer = shap.TreeExplainer(model)\n",
        "            shap_values = explainer.shap_values(X_test.iloc[:100])  # 샘플만\n",
        "\n",
        "            # 피쳐 중요도\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': feature_names,\n",
        "                'importance': np.abs(shap_values).mean(axis=0)\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            print(\"\\nTop 20 중요 피쳐:\")\n",
        "            print(feature_importance.head(20))\n",
        "\n",
        "            return feature_importance\n",
        "        except ImportError:\n",
        "            print(\"SHAP 라이브러리가 설치되지 않았습니다. pip install shap\")\n",
        "            return None\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 5. 메인 실행 파이프라인\n",
        "# ====================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"전체 파이프라인 실행\"\"\"\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"금융결제원 AML 탐지 프로젝트 시작\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # ========== 1. 데이터 로드 ==========\n",
        "    loader = AMLDataLoader(\n",
        "        trans_path=trans_path,\n",
        "        accounts_path=accounts_path\n",
        "    )\n",
        "\n",
        "    df_trans, df_accounts = loader.load_data()\n",
        "    df_trans = loader.explore_data(df_trans, df_accounts)\n",
        "\n",
        "    # ========== 2. 전처리 및 샘플링 ==========\n",
        "    preprocessor = AMLPreprocessor(sample_ratio=0.1)\n",
        "\n",
        "    # 시간 단위 배치 샘플 생성\n",
        "    all_trans, account_time_labels = preprocessor.create_hourly_samples(df_trans)\n",
        "\n",
        "    # 자금세탁 패턴 분석\n",
        "    laundering, normal = preprocessor.analyze_laundering_patterns(df_trans)\n",
        "\n",
        "    # 샘플링 (큰 데이터를 작게)\n",
        "    sampled_labels = preprocessor.stratified_sample(account_time_labels)\n",
        "\n",
        "    # ========== 3. 피쳐 생성 ==========\n",
        "    feature_engineer = FeatureEngineer()\n",
        "\n",
        "    # 집계 피쳐 생성\n",
        "    print(\"\\n⚠️ 주의: 전체 데이터에 대해 피쳐를 생성하려면 시간이 오래 걸립니다.\")\n",
        "    print(\"시연을 위해 1000건만 생성합니다.\")\n",
        "    agg_features = feature_engineer.create_aggregation_features(\n",
        "        all_trans,\n",
        "        sampled_labels\n",
        "    )\n",
        "\n",
        "    # 그래프 피쳐 생성\n",
        "    graph_features = feature_engineer.create_graph_features(\n",
        "        all_trans,\n",
        "        sampled_labels\n",
        "    )\n",
        "\n",
        "    # 피쳐 병합\n",
        "    all_features = agg_features.merge(\n",
        "        graph_features,\n",
        "        on=['Account', 'TimeUnit'],\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n전체 피쳐 수: {len([c for c in all_features.columns if c not in ['Account', 'TimeUnit']])}\")\n",
        "\n",
        "    # ========== 4. 모델 학습 ==========\n",
        "    trainer = AMLModelTrainer()\n",
        "\n",
        "    # Train/Test 분할\n",
        "    X_train, X_test, y_train, y_test, test_df = trainer.prepare_train_test_split(\n",
        "        all_features,\n",
        "        sampled_labels\n",
        "    )\n",
        "\n",
        "    # Baseline 모델 학습\n",
        "    baseline_model, y_pred_proba = trainer.train_baseline_model(\n",
        "        X_train, y_train, X_test, y_test,\n",
        "        use_smote=False,  # SMOTE 사용 여부\n",
        "        scale_pos_weight=None  # Auto 계산\n",
        "    )\n",
        "\n",
        "    # ========== 5. 평가 ==========\n",
        "    # Top-K 평가\n",
        "    topk_results = trainer.evaluate_topk(\n",
        "        y_test.values,\n",
        "        y_pred_proba,\n",
        "        test_df,\n",
        "        k_values=[50, 100, 200]\n",
        "    )\n",
        "\n",
        "    # Feature Importance (XAI)\n",
        "    feature_names = [c for c in X_train.columns]\n",
        "    feature_importance = trainer.explain_with_shap(\n",
        "        baseline_model,\n",
        "        X_train,\n",
        "        X_test,\n",
        "        feature_names\n",
        "    )\n",
        "\n",
        "    # ========== 6. 결과 저장 ==========\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"프로젝트 완료!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(\"\\n다음 단계:\")\n",
        "    print(\"1. 그래프 피쳐 추가 전후 성능 비교\")\n",
        "    print(\"2. 시계열 모델 앙상블\")\n",
        "    print(\"3. GNN 모델 적용\")\n",
        "    print(\"4. K-Fold Cross Validation으로 안정성 검증\")\n",
        "\n",
        "    return {\n",
        "        'baseline_model': baseline_model,\n",
        "        'topk_results': topk_results,\n",
        "        'feature_importance': feature_importance\n",
        "    }\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 추가: GNN 모델 (향후 구현)\n",
        "# ====================================\n",
        "\n",
        "class GNNModel:\n",
        "    \"\"\"Graph Neural Network for AML Detection\n",
        "    향후 구현 예정:\n",
        "    - GraphSAGE\n",
        "    - GAT (Graph Attention Network)\n",
        "    - Temporal GNN\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"GNN 모델은 PyTorch Geometric 라이브러리 필요\")\n",
        "        print(\"pip install torch-geometric\")\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"GNN 모델 구축\"\"\"\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"GNN 학습\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 실행\n",
        "    results = main()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"사용 예시:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\"\"\n",
        "    # 1. 데이터 로드\n",
        "    loader = AMLDataLoader('HI-Small_Trans.csv', 'HI-Small_accounts.csv')\n",
        "    df_trans, df_accounts = loader.load_data()\n",
        "\n",
        "    # 2. 전처리\n",
        "    preprocessor = AMLPreprocessor(sample_ratio=0.1)\n",
        "    all_trans, account_time_labels = preprocessor.create_hourly_samples(df_trans)\n",
        "\n",
        "    # 3. 피쳐 생성\n",
        "    feature_engineer = FeatureEngineer()\n",
        "    features = feature_engineer.create_aggregation_features(all_trans, account_time_labels)\n",
        "\n",
        "    # 4. 모델 학습\n",
        "    trainer = AMLModelTrainer()\n",
        "    X_train, X_test, y_train, y_test, test_df = trainer.prepare_train_test_split(features, account_time_labels)\n",
        "    model, predictions = trainer.train_baseline_model(X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # 5. 평가\n",
        "    results = trainer.evaluate_topk(y_test, predictions, test_df)\n",
        "    \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b7OmeFb3v1cf",
        "outputId": "2e7d9bbf-a04b-4b80-c2c3-fada15c104a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "금융결제원 AML 탐지 프로젝트 시작\n",
            "================================================================================\n",
            "================================================================================\n",
            "데이터 로딩 중...\n",
            "거래 데이터 shape: (5078345, 11)\n",
            "계좌 데이터 shape: (518581, 5)\n",
            "\n",
            "================================================================================\n",
            "데이터 탐색\n",
            "================================================================================\n",
            "\n",
            "[거래 데이터 샘플]\n",
            "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "0  2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
            "1  2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
            "2  2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
            "3  2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
            "4  2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
            "\n",
            "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "0          3697.34          US Dollar      3697.34        US Dollar   \n",
            "1             0.01          US Dollar         0.01        US Dollar   \n",
            "2         14675.57          US Dollar     14675.57        US Dollar   \n",
            "3          2806.97          US Dollar      2806.97        US Dollar   \n",
            "4         36682.97          US Dollar     36682.97        US Dollar   \n",
            "\n",
            "  Payment Format  Is Laundering  \n",
            "0   Reinvestment              0  \n",
            "1         Cheque              0  \n",
            "2   Reinvestment              0  \n",
            "3   Reinvestment              0  \n",
            "4   Reinvestment              0  \n",
            "\n",
            "컬럼: ['Timestamp', 'From Bank', 'Account', 'To Bank', 'Account.1', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency', 'Payment Format', 'Is Laundering']\n",
            "\n",
            "결측치:\n",
            "Timestamp             0\n",
            "From Bank             0\n",
            "Account               0\n",
            "To Bank               0\n",
            "Account.1             0\n",
            "Amount Received       0\n",
            "Receiving Currency    0\n",
            "Amount Paid           0\n",
            "Payment Currency      0\n",
            "Payment Format        0\n",
            "Is Laundering         0\n",
            "dtype: int64\n",
            "\n",
            "[자금세탁 분포]\n",
            "Is Laundering\n",
            "0    5073168\n",
            "1       5177\n",
            "Name: count, dtype: int64\n",
            "자금세탁 비율: 0.1019%\n",
            "\n",
            "[시간 범위]\n",
            "시작: 2022-09-01 00:00:00\n",
            "종료: 2022-09-18 16:18:00\n",
            "\n",
            "[일별 자금세탁 분포]\n",
            "     sum    count      mean\n",
            "Day                        \n",
            "1    322  1114921  0.000289\n",
            "2    408   754449  0.000541\n",
            "3    391   207382  0.001885\n",
            "4    407   207430  0.001962\n",
            "5    471   482650  0.000976\n",
            "6    531   482089  0.001101\n",
            "7    497   482751  0.001030\n",
            "8    539   482773  0.001116\n",
            "9    514   654467  0.000785\n",
            "10   442   208325  0.002122\n",
            "11   232      396  0.585859\n",
            "12   170      281  0.604982\n",
            "13   106      184  0.576087\n",
            "14    70      121  0.578512\n",
            "15    28       46  0.608696\n",
            "16    26       46  0.565217\n",
            "17    15       23  0.652174\n",
            "18     8       11  0.727273\n",
            "\n",
            "⚠️ Day 피쳐의 label 분포가 치우쳐져 있습니다. 제거 고려 필요\n",
            "\n",
            "[계좌 데이터 샘플]\n",
            "                     Bank Name  Bank ID Account Number  Entity ID  \\\n",
            "0          Portugal Bank #4507   331579      80B779D80  80062E240   \n",
            "1              Canada Bank #27      210      809D86900  800C998A0   \n",
            "2                  UK Bank #33    21884      80812BE00  800C47F50   \n",
            "3           Germany Bank #4815    32742      81047F300  80096F0B0   \n",
            "4  National Bank of Harrisburg   127390      80BD8CF00  800FB8760   \n",
            "\n",
            "                  Entity Name  \n",
            "0  Sole Proprietorship #50438  \n",
            "1          Corporation #33520  \n",
            "2          Partnership #35397  \n",
            "3          Corporation #48813  \n",
            "4            Corporation #889  \n",
            "\n",
            "은행 분포:\n",
            "Bank Name\n",
            "National Bank of Laramie       3797\n",
            "National Bank of the East      3663\n",
            "Japan Bank #0                  3051\n",
            "Arbor Savings Bank             2894\n",
            "National Bank of Pittsburgh    2683\n",
            "Savings Bank of Fairfield      2642\n",
            "First Bank of Tampa            2464\n",
            "Savings Bank of Huron          2379\n",
            "Savings Bank of Los Angeles    2052\n",
            "Golden Bancorp                 1967\n",
            "Name: count, dtype: int64\n",
            "\n",
            "================================================================================\n",
            "시간 단위 배치 샘플 생성\n",
            "================================================================================\n",
            "총 샘플 수 (계좌-시간 단위): 4586703\n",
            "자금세탁 샘플: 10058\n",
            "\n",
            "================================================================================\n",
            "자금세탁 패턴 분석\n",
            "================================================================================\n",
            "\n",
            "[거래 금액 통계]\n",
            "자금세탁 - 평균: $36135310.41, 중앙값: $8667.21\n",
            "정상 거래 - 평균: $5957962.48, 중앙값: $1407.51\n",
            "\n",
            "[결제 수단 분포]\n",
            "자금세탁:\n",
            "Receiving Currency\n",
            "US Dollar      1912\n",
            "Euro           1372\n",
            "Saudi Riyal     374\n",
            "Swiss Franc     193\n",
            "Yuan            184\n",
            "Name: count, dtype: int64\n",
            "\n",
            "정상 거래:\n",
            "Receiving Currency\n",
            "US Dollar      1877429\n",
            "Euro           1170645\n",
            "Swiss Franc     237691\n",
            "Yuan            206367\n",
            "Shekel          194893\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[시간대 분포]\n",
            "자금세탁 - 시간대별:\n",
            "Hour\n",
            "0     176\n",
            "1     152\n",
            "2     165\n",
            "3     146\n",
            "4     154\n",
            "5     188\n",
            "6     207\n",
            "7     195\n",
            "8     258\n",
            "9     217\n",
            "10    234\n",
            "11    295\n",
            "12    336\n",
            "13    292\n",
            "14    279\n",
            "15    263\n",
            "16    311\n",
            "17    257\n",
            "18    255\n",
            "19    231\n",
            "20    134\n",
            "21    154\n",
            "22    128\n",
            "23    150\n",
            "Name: count, dtype: int64\n",
            "\n",
            "계층화 샘플링 (비율: 0.1)\n",
            "샘플링 후 크기: 458669\n",
            "자금세탁 비율: 0.2191%\n",
            "\n",
            "⚠️ 주의: 전체 데이터에 대해 피쳐를 생성하려면 시간이 오래 걸립니다.\n",
            "시연을 위해 1000건만 생성합니다.\n",
            "\n",
            "================================================================================\n",
            "집계 피쳐 생성\n",
            "================================================================================\n",
            "진행: 0/458669\n",
            "\n",
            "생성된 피쳐 수: 58\n",
            "피쳐 목록 (처음 10개): ['out_count_1h', 'out_amount_sum_1h', 'out_amount_mean_1h', 'out_amount_std_1h', 'out_amount_max_1h', 'in_count_1h', 'in_amount_sum_1h', 'in_amount_mean_1h', 'in_amount_std_1h', 'in_amount_max_1h']\n",
            "\n",
            "================================================================================\n",
            "그래프 피쳐 생성\n",
            "================================================================================\n",
            "그래프 구축 완료 - 노드: 1533021, 엣지: 1632567\n",
            "Centrality 계산 중...\n",
            "그래프 피쳐 생성 완료 - 피쳐 수: 9\n",
            "\n",
            "전체 피쳐 수: 67\n",
            "\n",
            "================================================================================\n",
            "Train/Test 분할\n",
            "================================================================================\n",
            "Train set: 0 (자금세탁: 0)\n",
            "Test set: 0 (자금세탁: 0)\n",
            "Train 자금세탁 비율: nan%\n",
            "Test 자금세탁 비율: nan%\n",
            "\n",
            "================================================================================\n",
            "Baseline 모델 학습 (XGBoost)\n",
            "================================================================================\n",
            "학습 데이터: 0건\n",
            "테스트 데이터: 0건\n",
            "Positive 비율 (Train): nan%\n",
            "Positive 비율 (Test): nan%\n",
            "⚠️ 학습 데이터에 Positive 샘플이 없습니다!\n",
            "scale_pos_weight: 1.00\n",
            "base_score: 0.9900\n",
            "학습 완료!\n",
            "\n",
            "================================================================================\n",
            "Top-K 평가\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "zero-size array to reduction operation minimum which has no identity",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-341327028.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0;31m# 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-341327028.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0;31m# ========== 5. 평가 ==========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Top-K 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m     topk_results = trainer.evaluate_topk(\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0my_pred_proba\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-341327028.py\u001b[0m in \u001b[0;36mevaluate_topk\u001b[0;34m(self, y_true, y_pred_proba, test_df, k_values)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;31m# 점수 스케일링 (1000점 만점)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred_proba\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     47\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
          ]
        }
      ]
    }
  ]
}